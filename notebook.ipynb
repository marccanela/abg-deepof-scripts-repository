{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepOF notebook for Busquets-Garcia Lab\n",
    "Welcome to this notebook, where you'll find all the code necessary to analyze your DeepLabCut (DLC) output with DeepOF. Don't worry! You don't need notions of coding with Python, as you'll need to run the cells of this notebook. Just keep reading, and I'll guide you through the following steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the necessary packages and directories\n",
    "First, run the following cell to import the necessary packages for your analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-18 12:51:35.374554: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-18 12:51:35.374641: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-18 12:51:35.453698: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-18 12:51:35.614131: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-18 12:51:36.658270: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-01-18 12:51:43.113606: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-18 12:51:43.259067: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-18 12:51:43.259315: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-18 12:51:43.262220: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-18 12:51:43.262420: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-18 12:51:43.262601: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-18 12:51:43.268543: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-18 12:51:43.268757: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-18 12:51:43.268951: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-18 12:51:43.269083: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9220 MB memory:  -> device: 0, name: NVIDIA RTX A4000, pci bus id: 0000:06:00.0, compute capability: 8.6\n",
      "/home/sie/miniconda3/envs/deepof/lib/python3.9/site-packages/ot/backend.py:2998: UserWarning: To use TensorflowBackend, you need to activate the tensorflow numpy API. You can activate it by running: \n",
      "from tensorflow.python.ops.numpy_ops import np_config\n",
      "np_config.enable_numpy_behavior()\n",
      "  register_backend(TensorflowBackend())\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import deepof.data\n",
    "\n",
    "import deepof.visuals\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to add your directories. Modify the following to fit the directories where you store your files:\n",
    "NOTE: run the corrected videos with the DLC files of the corrected videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_output = '/home/sie/Desktop/marc/multianimal spc/'\n",
    "directory_dlc = '/home/sie/Desktop/marc/multianimal spc/csv/'\n",
    "directory_videos = '/home/sie/Desktop/marc/multianimal spc/videos/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create your DeepOF project folder\n",
    "Now that you have all set, it's time to start your analysis. Just run the following cell to create a folder with your DeepOF project (where you'll perform your study). But before, take into consideration:\n",
    "- To draw an area, click on the corners of the arena. Press **d** to delete and **q** once you have finished.\n",
    "- The first edge that you draw will be used to escalate from pixels to millimeters. The default value is 200 mm, corresponding to the longest edge of the polybox.\n",
    "- We will perform the arena detection semi-automatically. You'll have to draw the arena once, and the rest will be predicted based on your first attempt. The program will create a folder named *Arena_detection* to store samples of the automatic detection so you can check if everything went smoothly.\n",
    "- If you want to perform a manual drawing in each video (it may be tedious!), you can do it by switching **manual=False** to **manual=True** in the function below.\n",
    "- If you have a problem drawing the arena of a specific video, don't worry! Note the number of the video causing problems, draw any shape, and go on. After the analysis is completed, run the next cell indicating the video's name and re-draw the arena's shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Unequal number of videos and tables. Please check your file structure",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmaster_script\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m creating_deepof_project\n\u001b[0;32m----> 2\u001b[0m my_deepof_project \u001b[38;5;241m=\u001b[39m \u001b[43mcreating_deepof_project\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirectory_dlc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirectory_videos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmanual\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/marc/git/abg-deepof-scripts-repository/master_script.py:30\u001b[0m, in \u001b[0;36mcreating_deepof_project\u001b[0;34m(directory_output, directory_dlc, directory_videos, manual, scale)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m manual \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     29\u001b[0m     arena_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpolygonal-manual\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 30\u001b[0m my_deepof_project \u001b[38;5;241m=\u001b[39m \u001b[43mdeepof\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProject\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mproject_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory_output\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory_videos\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mtable_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory_dlc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mproject_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdeepof_tutorial_project\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m                    \u001b[49m\u001b[43marena\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marena_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;66;43;03m# animal_ids=[\"Animal_1\", 'Animal_2'],\u001b[39;49;00m\n\u001b[1;32m     37\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvideo_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.avi\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;66;43;03m# exclude_bodyparts=[\"Tail_1\", \"Tail_2\", \"Tail_tip\"],\u001b[39;49;00m\n\u001b[1;32m     39\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvideo_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# in mm\u001b[39;49;00m\n\u001b[1;32m     40\u001b[0m \u001b[43m                    \u001b[49m\u001b[43menable_iterative_imputation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msmooth_alpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mexp_conditions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Creating a DeepOF project:\u001b[39;00m\n\u001b[1;32m     46\u001b[0m my_deepof_project \u001b[38;5;241m=\u001b[39m my_deepof_project\u001b[38;5;241m.\u001b[39mcreate(force\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/deepof/lib/python3.9/site-packages/deepof/data.py:164\u001b[0m, in \u001b[0;36mProject.__init__\u001b[0;34m(self, animal_ids, arena, bodypart_graph, enable_iterative_imputation, exclude_bodyparts, exp_conditions, interpolate_outliers, interpolation_limit, interpolation_std, likelihood_tol, model, project_name, project_path, video_path, table_path, rename_bodyparts, sam_checkpoint_path, smooth_alpha, table_format, video_format, video_scale)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvideos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\n\u001b[1;32m    151\u001b[0m     [\n\u001b[1;32m    152\u001b[0m         vid\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    155\u001b[0m     ]\n\u001b[1;32m    156\u001b[0m )\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\n\u001b[1;32m    158\u001b[0m     [\n\u001b[1;32m    159\u001b[0m         tab\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    162\u001b[0m     ]\n\u001b[1;32m    163\u001b[0m )\n\u001b[0;32m--> 164\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvideos) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtables\n\u001b[1;32m    166\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnequal number of videos and tables. Please check your file structure\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# Loads arena details and (if needed) detection models\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marena \u001b[38;5;241m=\u001b[39m arena\n",
      "\u001b[0;31mAssertionError\u001b[0m: Unequal number of videos and tables. Please check your file structure"
     ]
    }
   ],
   "source": [
    "from master_script import creating_deepof_project\n",
    "my_deepof_project = creating_deepof_project(directory_output, directory_dlc, directory_videos, manual=False, scale=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To re-draw the shape of an arena\n",
    "my_deepof_project.edit_arenas(videos=['20230728_Marc_ERC SOC S1_Males_box ef_05_01_1',\n",
    "                                      '20230728_Marc_ERC SOC S2_Males_box ab_04_01_1',\n",
    "                                      '20230728_Marc_ERC SOC S2_Males_box ab_06_01_1',\n",
    "                                      '20230728_Marc_ERC SOC S2_Males_box cd_04_01_1'\n",
    "                                      ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you may add some conditions to your experiment (e.g., a column named *protocol* in which you indicate the group to which the video belongs). To do so, first, you must create a CSV file (you can do that in Excel and then export it to CSV) and store it in your _directory_output_. You cave an example named ``conditions.csv`` in this repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_deepof_project.load_exp_conditions(directory_output + \"conditions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: in case you want to check that your conditions have been correctly imported:\n",
    "from master_script import check_conditions\n",
    "check_conditions(directory_output, my_deepof_project, col_name='protocol')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a supervised analysis\n",
    "With the supervised analysis, you can predict different pre-defined behaviors. We start supposing that you created a DeepOF project (that is to say, that you ran the cells from the section above). In case you have a DeepOF project and you want to load it, run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_deepof_project = deepof.data.load_project(directory_output + \"deepof_tutorial_project\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once loaded with a DeepOF project, it's time to run the supervised analysis! For the sake of time, we'll store the output from the supervised analysis in a pickle file named **supervised_annotation.pkl**. Then, you can load it in the future and start working with it immediately without re-doing the analysis. In summary, to perform a new supervised analysis, run the first cell; to load an existing one, the second cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a new supervised analysis\n",
    "supervised_annotation = my_deepof_project.supervised_annotation()\n",
    "with open(directory_output + 'supervised_annotation.pkl', 'wb') as file:\n",
    "    pickle.dump(supervised_annotation, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, open an existing supervised analysis\n",
    "with open(directory_output + 'supervised_annotation.pkl', 'rb') as file:\n",
    "    supervised_annotation = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering that we have other data sources, we might think it would be interesting to merge all of them. Running the following cell, we can combine the output of Júlia's and Rémi's script for immobility analysis into the data of DeepOF. You must enter a folder directory where you store the pickle files obtained after the immobility analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from master_script import update_supervised_annotation_with_immobility\n",
    "\n",
    "directory_path = '//FOLDER/becell/Lab Projects/ERCstG_HighMemory/Data/Marc/1) SOC/2023-09 - Young males/DeepOF/Data/pickles/'\n",
    "update_supervised_annotation_with_immobility(supervised_annotation, directory_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform an unsupervised analysis\n",
    "With an unsupervised analysis, you can identify patterns in your data without labeling or a pre-existing hypothesis. Therefore, you can use it to explore your data and discover new relationships you wouldn't have noticed! First, we'll preprocess our data; DeepOF will calculate the centered and aligned coordinates, speeds, and distances corresponding between the animal parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from master_script import graph_dataset_function\n",
    "graph_preprocessed_coords, adj_matrix, to_preprocess, global_scaler = graph_dataset_function(my_deepof_project)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will embed our data with deep clustering methods. The core idea of deep clustering is to embed our preprocessed data with a neural network and retrieve a set of embeddings per time point, each assigned to a cluster. If you have already trained a model, set **pre_trained=True**** instead of *False*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from master_script import train_model_function\n",
    "trained_model = train_model_function(my_deepof_project, graph_preprocessed_coords, adj_matrix, pre_trained=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_deepof",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
